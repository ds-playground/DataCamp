{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building deep learning models with keras**\n",
    "\n",
    "In this chapter, you'll use the keras library to build deep learning models for both regression as well as classification! You'll learn about the Specify-Compile-Fit workflow that you can use to make predictions and by the end of this chapter, you'll have all the tools necessary to build deep neural networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding your data**\n",
    "\n",
    "You will soon start building models in Keras to predict wages based on various professional and demographic factors. Before you start building a model, it's good to understand your data by performing some exploratory analysis.\n",
    "\n",
    "The data is pre-loaded into a pandas DataFrame called `df`. Use the `.head()` and `.describe()` methods in the IPython Shell for a quick overview of the DataFrame.\n",
    "\n",
    "The target variable you'll be predicting is `wage_per_hour`. Some of the predictor variables are binary indicators, where a value of `1` represents `True`, and `0` represents `False`.\n",
    "\n",
    "Of the `9` predictor variables in the DataFrame, how many are binary indicators? The min and max values as shown by `.describe()` will be informative here. How many binary indicator predictors are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specifying a model**\n",
    "\n",
    "Now you'll get to work with your first model in Keras, and will immediately be able to run more complex neural network models on larger datasets compared to the first two chapters.\n",
    "\n",
    "To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. You'll then fit that model and see Keras do the optimization so your model continually gets better.\n",
    "\n",
    "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. You can find the dataset in a pandas dataframe called `df`. For convenience, everything in `df` except for the target has been converted to a NumPy matrix called `predictors`. The target, `wage_per_hour`, is available as a NumPy matrix called `target`.\n",
    "\n",
    "For all exercises in this chapter, we've imported the `Sequential` model constructor, the `Dense` layer constructor, and pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'Dense': keras.layers.core.Dense,\n",
    " 'In': ['', 'vara()', 'vars()'],\n",
    " 'Out': {},\n",
    " 'Sequential': keras.models.Sequential,\n",
    " '_': '',\n",
    " '__': '',\n",
    " '___': '',\n",
    " '__builtin__': <module 'builtins' (built-in)>,\n",
    " '__builtins__': <module 'builtins' (built-in)>,\n",
    " '__name__': '__main__',\n",
    " '_dh': ['/tmp/tmpeidmidax'],\n",
    " '_i': 'vara()',\n",
    " '_i1': 'vars()',\n",
    " '_ih': ['', 'vara()', 'vars()'],\n",
    " '_ii': '',\n",
    " '_iii': '',\n",
    " '_oh': {},\n",
    " '_sh': <module 'IPython.core.shadowns' from '/var/lib/python/site-packages/IPython/core/shadowns.py'>,\n",
    " 'df':      wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
    " 0             5.10      0              8              21   35       1     1   \n",
    " 1             4.95      0              9              42   57       1     1   \n",
    " 2             6.67      0             12               1   19       0     0   \n",
    " 3             4.00      0             12               4   22       0     0   \n",
    " 4             7.50      0             12              17   35       0     1   \n",
    " 5            13.07      1             13               9   28       0     0   \n",
    " 6             4.45      0             10              27   43       0     0   \n",
    " 7            19.47      0             12               9   27       0     0   \n",
    " 8            13.28      0             16              11   33       0     1   \n",
    " 9             8.75      0             12               9   27       0     0   \n",
    " 10           11.35      1             12              17   35       0     1   \n",
    " 11           11.50      1             12              19   37       0     0   \n",
    " 12            6.50      0              8              27   41       0     1   \n",
    " 13            6.25      1              9              30   45       0     0   \n",
    " 14           19.98      0              9              29   44       0     1   \n",
    " 15            7.30      0             12              37   55       0     1   \n",
    " 16            8.00      0              7              44   57       0     1   \n",
    " 17           22.20      1             12              26   44       0     1   \n",
    " 18            3.65      0             11              16   33       0     0   \n",
    " 19           20.55      0             12              33   51       0     1   \n",
    " 20            5.71      1             12              16   34       1     1   \n",
    " 21            7.00      1              7              42   55       0     1   \n",
    " 22            3.75      0             12               9   27       0     0   \n",
    " 23            4.50      0             11              14   31       0     1   \n",
    " 24            9.56      0             12              23   41       0     1   \n",
    " 25            5.75      0              6              45   57       0     1   \n",
    " 26            9.36      0             12               8   26       0     1   \n",
    " 27            6.50      0             10              30   46       0     1   \n",
    " 28            3.35      0             12               8   26       1     1   \n",
    " 29            4.75      0             12               8   26       0     1   \n",
    " ..             ...    ...            ...             ...  ...     ...   ...   \n",
    " 504          11.25      0             17              10   33       1     0   \n",
    " 505           6.67      1             16              10   32       1     0   \n",
    " 506           8.00      0             16              17   39       1     1   \n",
    " 507          18.16      0             18               7   31       0     1   \n",
    " 508          12.00      0             16              14   36       1     1   \n",
    " 509           8.89      1             16              22   44       1     1   \n",
    " 510           9.50      0             17              14   37       1     1   \n",
    " 511          13.65      0             16              11   33       0     1   \n",
    " 512          12.00      1             18              23   47       0     1   \n",
    " 513          15.00      1             12              39   57       0     1   \n",
    " 514          12.67      0             16              15   37       0     1   \n",
    " 515           7.38      0             14              15   35       1     0   \n",
    " 516          15.56      0             16              10   32       0     0   \n",
    " 517           7.45      0             12              25   43       1     0   \n",
    " 518           6.25      0             14              12   32       1     1   \n",
    " 519           6.25      0             16               7   29       1     1   \n",
    " 520           9.37      1             17               7   30       0     1   \n",
    " 521          22.50      0             16              17   39       0     1   \n",
    " 522           7.50      1             16              10   32       0     1   \n",
    " 523           7.00      0             17               2   25       0     1   \n",
    " 524           5.75      1              9              34   49       1     1   \n",
    " 525           7.67      0             15              11   32       1     1   \n",
    " 526          12.50      0             15              10   31       0     0   \n",
    " 527          16.00      0             12              12   30       0     1   \n",
    " 528          11.79      1             16               6   28       1     0   \n",
    " 529          11.36      0             18               5   29       0     0   \n",
    " 530           6.10      0             12              33   51       1     1   \n",
    " 531          23.25      1             17              25   48       1     1   \n",
    " 532          19.88      1             12              13   31       0     1   \n",
    " 533          15.38      0             16              33   55       0     1   \n",
    " \n",
    "      south  manufacturing  construction  \n",
    " 0        0              1             0  \n",
    " 1        0              1             0  \n",
    " 2        0              1             0  \n",
    " 3        0              0             0  \n",
    " 4        0              0             0  \n",
    " 5        0              0             0  \n",
    " 6        1              0             0  \n",
    " 7        0              0             0  \n",
    " 8        0              1             0  \n",
    " 9        0              0             0  \n",
    " 10       0              0             0  \n",
    " 11       0              1             0  \n",
    " 12       1              0             0  \n",
    " 13       1              0             0  \n",
    " 14       1              0             0  \n",
    " 15       0              0             1  \n",
    " 16       1              0             0  \n",
    " 17       0              1             0  \n",
    " 18       0              0             0  \n",
    " 19       0              0             0  \n",
    " 20       0              1             0  \n",
    " 21       0              1             0  \n",
    " 22       0              0             0  \n",
    " 23       1              0             0  \n",
    " 24       0              0             0  \n",
    " 25       1              1             0  \n",
    " 26       0              1             0  \n",
    " 27       0              0             0  \n",
    " 28       0              1             0  \n",
    " 29       0              0             0  \n",
    " ..     ...            ...           ...  \n",
    " 504      0              0             0  \n",
    " 505      0              0             0  \n",
    " 506      0              0             0  \n",
    " 507      0              0             0  \n",
    " 508      0              0             0  \n",
    " 509      0              0             0  \n",
    " 510      0              0             0  \n",
    " 511      0              0             0  \n",
    " 512      0              0             0  \n",
    " 513      0              0             0  \n",
    " 514      0              0             0  \n",
    " 515      0              0             0  \n",
    " 516      0              0             0  \n",
    " 517      1              0             0  \n",
    " 518      0              0             0  \n",
    " 519      1              0             0  \n",
    " 520      0              0             0  \n",
    " 521      0              1             0  \n",
    " 522      0              0             0  \n",
    " 523      1              0             0  \n",
    " 524      1              0             0  \n",
    " 525      0              0             0  \n",
    " 526      0              0             0  \n",
    " 527      1              0             0  \n",
    " 528      0              0             0  \n",
    " 529      0              0             0  \n",
    " 530      0              0             0  \n",
    " 531      0              0             0  \n",
    " 532      1              0             0  \n",
    " 533      0              1             0  \n",
    " \n",
    " [534 rows x 10 columns],\n",
    " 'exit': <IPython.core.autocall.ExitAutocall at 0x7fb620192358>,\n",
    " 'get_ipython': <bound method InteractiveShell.get_ipython of <IPython.core.interactiveshell.InteractiveShell object at 0x7fb611baebe0>>,\n",
    " 'keras': <module 'keras' from '/usr/local/lib/python3.5/dist-packages/keras/__init__.py'>,\n",
    " 'pd': <module 'pandas' from '/var/lib/python/site-packages/pandas/__init__.py'>,\n",
    " 'predictors': array([[ 0,  8, 21, ...,  0,  1,  0],\n",
    "        [ 0,  9, 42, ...,  0,  1,  0],\n",
    "        [ 0, 12,  1, ...,  0,  1,  0],\n",
    "        ..., \n",
    "        [ 1, 17, 25, ...,  0,  0,  0],\n",
    "        [ 1, 12, 13, ...,  1,  0,  0],\n",
    "        [ 0, 16, 33, ...,  0,  1,  0]]),\n",
    " 'quit': <IPython.core.autocall.ExitAutocall at 0x7fb620192358>,\n",
    " 'target': array([  5.1 ,   4.95,   6.67,   4.  ,   7.5 ,  13.07,   4.45,  19.47,\n",
    "         13.28,   8.75,  11.35,  11.5 ,   6.5 ,   6.25,  19.98,   7.3 ,\n",
    "          8.  ,  22.2 ,   3.65,  20.55,   5.71,   7.  ,   3.75,   4.5 ,\n",
    "          9.56,   5.75,   9.36,   6.5 ,   3.35,   4.75,   8.9 ,   4.  ,\n",
    "          4.7 ,   5.  ,   9.25,  10.67,   7.61,  10.  ,   7.5 ,  12.2 ,\n",
    "          3.35,  11.  ,  12.  ,   4.85,   4.3 ,   6.  ,  15.  ,   4.85,\n",
    "          9.  ,   6.36,   9.15,  11.  ,   4.5 ,   4.8 ,   4.  ,   5.5 ,\n",
    "          8.4 ,   6.75,  10.  ,   5.  ,   6.5 ,  10.75,   7.  ,  11.43,\n",
    "          4.  ,   9.  ,  13.  ,  12.22,   6.28,   6.75,   3.35,  16.  ,\n",
    "          5.25,   3.5 ,   4.22,   3.  ,   4.  ,  10.  ,   5.  ,  16.  ,\n",
    "         13.98,  13.26,   6.1 ,   3.75,   9.  ,   9.45,   5.5 ,   8.93,\n",
    "          6.25,   9.75,   6.73,   7.78,   2.85,   3.35,  19.98,   8.5 ,\n",
    "          9.75,  15.  ,   8.  ,  11.25,  14.  ,  10.  ,   6.5 ,   9.83,\n",
    "         18.5 ,  12.5 ,  26.  ,  14.  ,  10.5 ,  11.  ,  12.47,  12.5 ,\n",
    "         15.  ,   6.  ,   9.5 ,   5.  ,   3.75,  12.57,   6.88,   5.5 ,\n",
    "          7.  ,   4.5 ,   6.5 ,  12.  ,   5.  ,   6.5 ,   6.8 ,   8.75,\n",
    "          3.75,   4.5 ,   6.  ,   5.5 ,  13.  ,   5.65,   4.8 ,   7.  ,\n",
    "          5.25,   3.35,   8.5 ,   6.  ,   6.75,   8.89,  14.21,  10.78,\n",
    "          8.9 ,   7.5 ,   4.5 ,  11.25,  13.45,   6.  ,   4.62,  10.58,\n",
    "          5.  ,   8.2 ,   6.25,   8.5 ,  24.98,  16.65,   6.25,   4.55,\n",
    "         11.25,  21.25,  12.65,   7.5 ,  10.25,   3.35,  13.45,   4.84,\n",
    "         26.29,   6.58,  44.5 ,  15.  ,  11.25,   7.  ,  10.  ,  14.53,\n",
    "         20.  ,  22.5 ,   3.64,  10.62,  24.98,   6.  ,  19.  ,  13.2 ,\n",
    "         22.5 ,  15.  ,   6.88,  11.84,  16.14,  13.95,  13.16,   5.3 ,\n",
    "          4.5 ,  10.  ,  10.  ,  10.  ,   9.37,   5.8 ,  17.86,   1.  ,\n",
    "          8.8 ,   9.  ,  18.16,   7.81,  10.62,   4.5 ,  17.25,  10.5 ,\n",
    "          9.22,  15.  ,  22.5 ,   4.55,   9.  ,  13.33,  15.  ,   7.5 ,\n",
    "          4.25,  12.5 ,   5.13,   3.35,  11.11,   3.84,   6.4 ,   5.56,\n",
    "         10.  ,   5.65,  11.5 ,   3.5 ,   3.35,   4.75,  19.98,   3.5 ,\n",
    "          4.  ,   7.  ,   6.25,   4.5 ,  14.29,   5.  ,  13.75,  13.71,\n",
    "          7.5 ,   3.8 ,   5.  ,   9.42,   5.5 ,   3.75,   3.5 ,   5.8 ,\n",
    "         12.  ,   5.  ,   8.75,  10.  ,   8.5 ,   8.63,   9.  ,   5.5 ,\n",
    "         11.11,  10.  ,   5.2 ,   8.  ,   3.56,   5.2 ,  11.67,  11.32,\n",
    "          7.5 ,   5.5 ,   5.  ,   7.75,   5.25,   9.  ,   9.65,   5.21,\n",
    "          7.  ,  12.16,   5.25,  10.32,   3.35,   7.7 ,   9.17,   8.43,\n",
    "          4.  ,   4.13,   3.  ,   4.25,   7.53,  10.53,   5.  ,  15.03,\n",
    "         11.25,   6.25,   3.5 ,   6.85,  12.5 ,  12.  ,   6.  ,   9.5 ,\n",
    "          4.1 ,  10.43,   5.  ,   7.69,   5.5 ,   6.4 ,  12.5 ,   6.25,\n",
    "          8.  ,   9.6 ,   9.1 ,   7.5 ,   5.  ,   7.  ,   3.55,   8.5 ,\n",
    "          4.5 ,   7.88,   5.25,   5.  ,   9.33,  10.5 ,   7.5 ,   9.5 ,\n",
    "          9.6 ,   5.87,  11.02,   5.  ,   5.62,  12.5 ,  10.81,   5.4 ,\n",
    "          7.  ,   4.59,   6.  ,  11.71,   5.62,   5.5 ,   4.85,   6.75,\n",
    "          4.25,   5.75,   3.5 ,   3.35,  10.62,   8.  ,   4.75,   8.5 ,\n",
    "          8.85,   8.  ,   6.  ,   7.14,   3.4 ,   6.  ,   3.75,   8.89,\n",
    "          4.35,  13.1 ,   4.35,   3.5 ,   3.8 ,   5.26,   3.35,  16.26,\n",
    "          4.25,   4.5 ,   8.  ,   4.  ,   7.96,   4.  ,   4.15,   5.95,\n",
    "          3.6 ,   8.75,   3.4 ,   4.28,   5.35,   5.  ,   7.65,   6.94,\n",
    "          7.5 ,   3.6 ,   1.75,   3.45,   9.63,   8.49,   8.99,   3.65,\n",
    "          3.5 ,   3.43,   5.5 ,   6.93,   3.51,   3.75,   4.17,   9.57,\n",
    "         14.67,  12.5 ,   5.5 ,   5.15,   8.  ,   5.83,   3.35,   7.  ,\n",
    "         10.  ,   8.  ,   6.88,   5.55,   7.5 ,   8.93,   9.  ,   3.5 ,\n",
    "          5.77,  25.  ,   6.85,   6.5 ,   3.75,   3.5 ,   4.5 ,   2.01,\n",
    "          4.17,  13.  ,   3.98,   7.5 ,  13.12,   4.  ,   3.95,  13.  ,\n",
    "          9.  ,   4.55,   9.5 ,   4.5 ,   8.75,  10.  ,  18.  ,  24.98,\n",
    "         12.05,  22.  ,   8.75,  22.2 ,  17.25,   6.  ,   8.06,   9.24,\n",
    "         12.  ,  10.61,   5.71,  10.  ,  17.5 ,  15.  ,   7.78,   7.8 ,\n",
    "         10.  ,  24.98,  10.28,  15.  ,  12.  ,  10.58,   5.85,  11.22,\n",
    "          8.56,  13.89,   5.71,  15.79,   7.5 ,  11.25,   6.15,  13.45,\n",
    "          6.25,   6.5 ,  12.  ,   8.5 ,   8.  ,   5.75,  15.73,   9.86,\n",
    "         13.51,   5.4 ,   6.25,   5.5 ,   5.  ,   6.25,   5.75,  20.5 ,\n",
    "          5.  ,   7.  ,  18.  ,  12.  ,  20.4 ,  22.2 ,  16.42,   8.63,\n",
    "         19.38,  14.  ,  10.  ,  15.95,  20.  ,  10.  ,  24.98,  11.25,\n",
    "         22.83,  10.2 ,  10.  ,  14.  ,  12.5 ,   5.79,  24.98,   4.35,\n",
    "         11.25,   6.67,   8.  ,  18.16,  12.  ,   8.89,   9.5 ,  13.65,\n",
    "         12.  ,  15.  ,  12.67,   7.38,  15.56,   7.45,   6.25,   6.25,\n",
    "          9.37,  22.5 ,   7.5 ,   7.  ,   5.75,   7.67,  12.5 ,  16.  ,\n",
    "         11.79,  11.36,   6.1 ,  23.25,  19.88,  15.38]),\n",
    " 'to_categorical': <function keras.uti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling the model**\n",
    "\n",
    "You're now going to compile the model you specified earlier. To compile the model, you need to specify the optimizer and loss function to use. In the video, Dan mentioned that the Adam optimizer is an excellent choice. You can read more about it as well as other keras optimizers [here](https://keras.io/optimizers/#adam), and if you are really curious to learn more, you can read the [original paper](https://arxiv.org/abs/1412.6980v8) that introduced the Adam optimizer.\n",
    "\n",
    "In this exercise, you'll use the Adam optimizer and the mean squared error loss function. Go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python36-with-r]",
   "language": "python",
   "name": "Python [python36-with-r]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
